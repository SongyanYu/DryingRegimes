as_tibble
tt %>% as.tbl_cube(met_name = "Score") %>%
as_tibble()
tt %>% as.tbl_cube(met_name = "ll") %>%
as_tibble()
as.matrix(tt)
as.matrixc(tt) %>% as.tbl_cube(met_name = "ll") %>%
as_tibble()
as.matrix(tt) %>% as.tbl_cube(met_name = "ll") %>%
as_tibble()
as.table(tt) %>% as.tbl_cube(met_name = "ll") %>%
as_tibble()
tt>1
tt[tt<1]
tt[tt==1] <-NA
tt[tt>=.9] <-NA
tt[tt>=.8] <-NA
###### Check out correlation structure of data#####
# Source: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
# https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning
#
###################################################
tt = cor(sub[,c(-1,-4)])
tt[tt>=.9] <-NA
tt
View(tt)
###### Check out correlation structure of data#####
# Source: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
# https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning
#
###################################################
tt = cor(sub[,c(-1,-4)])
tt[tt<=.9] <-NA
View(tt)
c1.m
sub= c4
set.seed(42)
seed = sample(1:10000,100)
set.seed(1202)
seed = sample(1:10000,100)
i=10
print(i)
# # Set seed and split data
set.seed(seed[i])
print(seed[i])
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
testing$index = NULL
training$index = NULL
c1.m
rf = ranger(formula = kmeans ~.,
data = training,
num.trees = 400,
mtry = 10,
max.depth = 10,
sample.fraction = .8,
importance = 'impurity',
num.threads = 7,
oob.error = T)
rf
rf$variable.importance
as.data.frame(rf$variable.importance)
tt = as.data.frame(sort(rf$variable.importance,decreasing = F)) %>% top_n(15)
tt
tt = as.data.frame(sort(rf$variable.importance,decreasing = F))
tt
tt = as.data.frame(sort(rf$variable.importance,decreasing = T))
tt = as.data.frame(head(sort(rf$variable.importance,decreasing = T),15))
tt
sub= c1
set.seed(1202)
seed = sample(1:10000,100)
i=10
print(i)
# # Set seed and split data
set.seed(seed[i])
print(seed[i])
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
testing$index = NULL
training$index = NULL
c1.m
rf = ranger(formula = kmeans ~.,
data = training,
num.trees = 400,
mtry = 10,
max.depth = 10,
sample.fraction = .8,
importance = 'impurity',
num.threads = 7,
oob.error = T)
tt = as.data.frame(head(sort(rf$variable.importance,decreasing = T),15))
tt
c1 %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90, P.PET,P.PET90
)
sub= c1
sub$DEVNLCD06
c1 = c1 %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90, P.PET,P.PET90
)
sub= c1
colnames(c1)
set.seed(1202)
seed = sample(1:10000,100)
i=10
print(i)
# # Set seed and split data
set.seed(seed[i])
print(seed[i])
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
testing$index = NULL
training$index = NULL
rf = ranger(formula = kmeans ~.,
data = training,
num.trees = 400,
mtry = 10,
max.depth = 10,
sample.fraction = .8,
importance = 'impurity',
num.threads = 7,
oob.error = T)
tt = as.data.frame(head(sort(rf$variable.importance,decreasing = T),15))
tt
rf$predictions
rf$num.independent.variables
rf$prediction.error
rf$importance.mode
rf$splitrule
########### Load and plot models ############
h2o.init(max_mem_size = '4G')
am = h2o.loadModel('data/rf_model/all_model')
h2o.varimp_plot(am,num_of_features = 30)
am
am$confusion
am$
am@have_mojo
am@algorithm
am@model
sub = df %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
DEVNLCD06,FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,ELEV_MEAN_M_BASIN,
SLOPE_PCT,AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,TOPWET,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,Tmin_C,Tmax_C,Srad_wm2,SWE_mm,melt_mm,
P_7,PET_7,Tmax_7,Tmin_7,melt_7,
P_14,PET_14,Tmax_14,Tmin_14,melt_14,
P_30,PET_30,Tmax_30,Tmin_30,melt_30,
P_60,PET_60,Tmax_60,Tmin_60,melt_60,
P_90,PET_90,Tmax_90,Tmin_90,melt_90,
P_180,PET_180,Tmax_180,Tmin_180,melt_180,
API_7,API_14,API_40,API_60,API_90,API_180,APETI_7,APETI_14,APETI_40,
APETI_60,APETI_90,APETI_180,AMELTI_7,AMELTI_14,AMELTI_40,AMELTI_60,AMELTI_90,AMELTI_180)
sub = sub %>%  select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90
)%>%
mutate(P.PET = P_mm/PET_mm,
P.PET90 = P_90/PET_90
)
sub[is.na(sub$P.PET),'P.PET']=0
sub = sub %>% filter_all(all_vars(!is.infinite(.)))
#### Clean up data
rm(ant.cond,clust,dat)
###### Check out correlation structure of data#####
# Source: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
# https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning
#
###################################################
tt = cor(sub[,c(-1,-4)])
corrplot::corrplot(tt,order='hclust',type = "upper")
rm(tt)
# Set seed and split data
set.seed(42)
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
index = sub$index
sub$index= NULL
testing$index = NULL
training$index = NULL
# create feature names
y <- "kmeans"
x <- setdiff(names(training), y)
# turn training set into h2o object
train.h2o <- as.h2o(training)
test.h2o <- as.h2o(testing)
best_model_perf <- h2o.performance(model = am, newdata = test.h2o)
best_model_perf
h2o.partialPlot(am,test.h2o,col_pairs_2dpdp=list(c("P_90","PET_90"),c("P_90","Tmax_C")))
h2o.partialPlot(am,test.h2o,col_pairs_2dpdp=list(c("P_90","PET_90"),c("P_90","Tmax_C")),targets=c('1','2'))
h2o.partialPlot(am,test.h2o,col_pairs_2dpdp=list(c("P_90","PET_90"),c("P_90","Tmax_C")),targets=c('1'))
install.packages("pdp")
library(pdp)
p1 <- partial(rf, pred.var = "kmeans", plot = TRUE, rug = TRUE)
p1 <- partial(rf, pred.var = "P_mm", plot = TRUE, rug = TRUE)
p1 <- partial(rf, pred.var = "P_mm", plot = TRUE)
autoplot.partial(rf)
pdp::plotPartial(object = rf)
install.packages("DALEX")
tt = DALEX::variable_importance(am)
tt = DALEX::variable_importance(best_model_id)
training$kmeans
training[,-'kmeans']
training[,-1]
x_valid = training[,-1]
y_valid = training[,1]
pred <- function(model, newdata)  {
results <- as.data.frame(h2o.predict(model, as.h2o(newdata)))
return(results[[3L]])
}
pred(am, x_valid) %>% head()
head(pred)
pred(rf, x_valid) %>% head()
pred(am, x_valid) %>% head()
sub = df %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
DEVNLCD06,FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,ELEV_MEAN_M_BASIN,
SLOPE_PCT,AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,TOPWET,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,Tmin_C,Tmax_C,Srad_wm2,SWE_mm,melt_mm,
P_7,PET_7,Tmax_7,Tmin_7,melt_7,
P_14,PET_14,Tmax_14,Tmin_14,melt_14,
P_30,PET_30,Tmax_30,Tmin_30,melt_30,
P_60,PET_60,Tmax_60,Tmin_60,melt_60,
P_90,PET_90,Tmax_90,Tmin_90,melt_90,
P_180,PET_180,Tmax_180,Tmin_180,melt_180,
API_7,API_14,API_40,API_60,API_90,API_180,APETI_7,APETI_14,APETI_40,
APETI_60,APETI_90,APETI_180,AMELTI_7,AMELTI_14,AMELTI_40,AMELTI_60,AMELTI_90,AMELTI_180)
sub = sub %>%  select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90
)%>%
mutate(P.PET = P_mm/PET_mm,
P.PET90 = P_90/PET_90
)
sub[is.na(sub$P.PET),'P.PET']=0
sub = sub %>% filter_all(all_vars(!is.infinite(.)))
#### Clean up data
rm(ant.cond,clust,dat)
# Set seed and split data
set.seed(42)
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
index = sub$index
sub$index= NULL
testing$index = NULL
training$index = NULL
x_valid = training[,-1]
y_valid = training[,1]
pred <- function(model, newdata)  {
results <- as.data.frame(h2o.predict(model, as.h2o(newdata)))
return(results[[3L]])
}
pred(am, x_valid) %>% head()
sub = df %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,ELEV_MEAN_M_BASIN,
SLOPE_PCT,AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,TOPWET,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,Tmin_C,Tmax_C,Srad_wm2,SWE_mm,melt_mm,
P_7,PET_7,Tmax_7,Tmin_7,melt_7,
P_14,PET_14,Tmax_14,Tmin_14,melt_14,
P_30,PET_30,Tmax_30,Tmin_30,melt_30,
P_60,PET_60,Tmax_60,Tmin_60,melt_60,
P_90,PET_90,Tmax_90,Tmin_90,melt_90,
P_180,PET_180,Tmax_180,Tmin_180,melt_180,
API_7,API_14,API_40,API_60,API_90,API_180,APETI_7,APETI_14,APETI_40,
APETI_60,APETI_90,APETI_180,AMELTI_7,AMELTI_14,AMELTI_40,AMELTI_60,AMELTI_90,AMELTI_180)
sub = sub %>%  select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90
)%>%
mutate(P.PET = P_mm/PET_mm,
P.PET90 = P_90/PET_90
)
sub[is.na(sub$P.PET),'P.PET']=0
sub = sub %>% filter_all(all_vars(!is.infinite(.)))
#### Clean up data
rm(ant.cond,clust,dat)
###### Check out correlation structure of data#####
# Source: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
# https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning
#
###################################################
tt = cor(sub[,c(-1,-4)])
corrplot::corrplot(tt,order='hclust',type = "upper")
c1 = sub %>%
mutate(kmeans = recode(kmeans,
'2'='0',
'3'='0',
'4'='0'))
c2 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2' = '1',
'3'='0',
'4'='0'))
c3 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2'='0',
'3' ='1',
'4'='0'))
c4 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2'='0',
'3'='0',
'4'='1'))
sub = c4
sub = df %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,ELEV_MEAN_M_BASIN,
SLOPE_PCT,AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,TOPWET,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,Tmin_C,Tmax_C,Srad_wm2,SWE_mm,melt_mm,
P_7,PET_7,Tmax_7,Tmin_7,melt_7,
P_14,PET_14,Tmax_14,Tmin_14,melt_14,
P_30,PET_30,Tmax_30,Tmin_30,melt_30,
P_60,PET_60,Tmax_60,Tmin_60,melt_60,
P_90,PET_90,Tmax_90,Tmin_90,melt_90,
P_180,PET_180,Tmax_180,Tmin_180,melt_180,
API_7,API_14,API_40,API_60,API_90,API_180,APETI_7,APETI_14,APETI_40,
APETI_60,APETI_90,APETI_180,AMELTI_7,AMELTI_14,AMELTI_40,AMELTI_60,AMELTI_90,AMELTI_180)
sub = sub %>%  select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90
)%>%
mutate(P.PET = P_mm/PET_mm,
P.PET90 = P_90/PET_90
)
sub[is.na(sub$P.PET),'P.PET']=0
sub = sub %>% filter_all(all_vars(!is.infinite(.)))
#### Clean up data
rm(ant.cond,clust,dat)
# Set seed and split data
set.seed(42)
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
index = sub$index
sub$index= NULL
testing$index = NULL
training$index = NULL
x_valid = training[,-1]
y_valid = training[,1]
x_valid = training[,-1]
y_valid = training[,1]
pred <- function(model, newdata)  {
results <- as.data.frame(h2o.predict(model, as.h2o(newdata)))
return(results[[3L]])
}
sub = df %>% select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
DEVNLCD06,FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,ELEV_MEAN_M_BASIN,
SLOPE_PCT,AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,TOPWET,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,Tmin_C,Tmax_C,Srad_wm2,SWE_mm,melt_mm,
P_7,PET_7,Tmax_7,Tmin_7,melt_7,
P_14,PET_14,Tmax_14,Tmin_14,melt_14,
P_30,PET_30,Tmax_30,Tmin_30,melt_30,
P_60,PET_60,Tmax_60,Tmin_60,melt_60,
P_90,PET_90,Tmax_90,Tmin_90,melt_90,
P_180,PET_180,Tmax_180,Tmin_180,melt_180,
API_7,API_14,API_40,API_60,API_90,API_180,APETI_7,APETI_14,APETI_40,
APETI_60,APETI_90,APETI_180,AMELTI_7,AMELTI_14,AMELTI_40,AMELTI_60,AMELTI_90,AMELTI_180)
sub = sub %>%  select(
kmeans,
DRAIN_SQKM,SNOW_PCT_PRECIP,GEOL_REEDBUSH_DOM,FRESHW_WITHDRAWAL,PCT_IRRIG_AG,
DEVNLCD06,FORESTNLCD06,PLANTNLCD06,WATERNLCD06,SNOWICENLCD06,IMPNLCD06,
AWCAVE,PERMAVE,CLAYAVE,SILTAVE,SANDAVE,
TOPWET,ELEV_MEAN_M_BASIN,
depth_bedrock_m,porosity,storage_m,
P_mm,PET_mm,SWE_mm,melt_mm,Tmax_C,
P_90,PET_90,Tmax_90,melt_90
)%>%
mutate(P.PET = P_mm/PET_mm,
P.PET90 = P_90/PET_90
)
sub[is.na(sub$P.PET),'P.PET']=0
sub = sub %>% filter_all(all_vars(!is.infinite(.)))
#### Clean up data
rm(ant.cond,clust,dat)
###### Check out correlation structure of data#####
# Source: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
# https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning
#
###################################################
tt = cor(sub[,c(-1,-4)])
corrplot::corrplot(tt,order='hclust',type = "upper")
rm(tt)
c1 = sub %>%
mutate(kmeans = recode(kmeans,
'2'='0',
'3'='0',
'4'='0'))
c2 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2' = '1',
'3'='0',
'4'='0'))
c3 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2'='0',
'3' ='1',
'4'='0'))
c4 = sub %>%
mutate(kmeans = recode(kmeans,
'1'='0',
'2'='0',
'3'='0',
'4'='1'))
sub = c4
# Set seed and split data
set.seed(42)
sub$index <- seq(1:nrow(sub))
training_size = round(nrow(sub)*0.7,0)
training <- as.data.frame(sub[sample(1:nrow(sub),training_size, replace = F),])
testing <- as.data.frame(sub[!sub$index %in% training$index,])
index = sub$index
sub$index= NULL
testing$index = NULL
training$index = NULL
# create feature names
y <- "kmeans"
x <- setdiff(names(training), y)
x_valid = training[,-1]
y_valid = training[,1]
pred <- function(model, newdata)  {
results <- as.data.frame(h2o.predict(model, as.h2o(newdata)))
return(results[[3L]])
}
c4.m = h2o.loadModel('data/rf_model/c4_model')
pred(c4.m, x_valid) %>% head()
explainer_rf <- explain(
model = c4.m,
data = x_valid,
y = y_valid,
predict_function = pred,
label = "h2o rf"
)
explainer_rf <- explain(
model = c4.m,
data = x_valid,
y = y_valid,
predict_function = pred,
label = "h2o rf"
)
explainer_rf <- DALEX::explain(
model = c4.m,
data = x_valid,
y = y_valid,
predict_function = pred,
label = "h2o rf"
)

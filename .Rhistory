}
# Use mpapply to exicute function
parallel::parLapply(cl,files,writeNF_feather)
files = list.files(here("data/reference/"),full.names = TRUE,pattern = '*csv')
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
writeNF_feather(files[1])
writeNF_feather <-function(files){
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files[i],metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files[100]),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,dat,root)
}
writeNF_feather(files[1])
ap_nf_length <- function(files,metric,threshold,nflength){
dat = fread(files,sep = ",", select = c(metric))
dat[which(dat<=threshold)]=-999
nf_period = rle(dat[[metric]])
nf_len = rep(nf_period$lengths, nf_period$lengths)
nf_len[which(nf_len <nflength)] = 1
nf_len[which(nf_len >=nflength)] = 0
return(nf_len)
}
writeNF_feather <-function(files){
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files[i],metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files[100]),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,dat,root)
}
writeNF_feather(files[1])
writeNF_feather <-function(files){
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files,metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files[100]),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,dat,root)
}
writeNF_feather(files[1])
writeNF_feather <-function(files){
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files,metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,dat,root)
}
writeNF_feather(files[1])
writeNF_feather <-function(files){
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files,metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,root)
}
writeNF_feather(files[1])
writeNF_feather <-function(files){
ap_nf_length <- function(files,metric,threshold,nflength){
dat = fread(files,sep = ",", select = c(metric))
dat[which(dat<=threshold)]=-999
nf_period = rle(dat[[metric]])
nf_len = rep(nf_period$lengths, nf_period$lengths)
nf_len[which(nf_len <nflength)] = 1
nf_len[which(nf_len >=nflength)] = 0
return(nf_len)
}
root = strsplit(files,'/')[[1]][10]
metric = 'Q_cfs'
threshold = 0.01
nfPeriods = c(3,5,7,14,30,60,90,180)
nf_len = list()
for (i in 1:length(nfPeriods)){
nf_len[[i]] = ap_nf_length(files,metric,threshold,nfPeriods[i])
}
names(nf_len) = paste0("NF",nfPeriods)
write.csv(cbind(read.csv(files),nf_len),paste0('data/reference/nfdata/',root))
rm(nf_len,root)
}
# Use mpapply to exicute function
parallel::parLapply(cl,files,writeNF_feather)
#
#
#
#
#
#
#
#
#
#
library(data.table)
library(here)
library(viridis)
files = list.files(here("data/reference/"),full.names = TRUE)
ap_pdf <- function(file,metric,threshold){
dat = fread(file,sep = ",", select = c(metric))
dat[is.na(dat)]=-999
nf_period = rle(dat[[metric]])
nf_period = nf_period$lengths[nf_period$values<=threshold  & nf_period$values>-999.0]
# plot(density(nf_period))
return(nf_period)
}
temp = ap_pdf(files[i],"Q_cfs",0.5)
i = 100
temp = ap_pdf(files[i],"Q_cfs",0.5)
i = 1
temp = ap_pdf(files[i],"Q_cfs",0.5)
plot(ecdf(temp))
files = list.files(here("data/reference/"),full.names = TRUE,pattern = '*csv')
for (i in 1:length(files)){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
png("plot.png",
width=1440,
height=1080)
plot(
ecdf(temp),
xlim = c(0,10),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
lines(
density(temp),
col = colpal[i],
add=T)
print(i)
}
}
files = list.files(here("data/reference/"),full.names = TRUE,pattern = '*csv')
for (i in 1:2){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
png("plot.png",
width=1440,
height=1080)
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp),
col = colpal[i],
add=T)
print(i)
}
}
plot(ecdf(temp)
)
dev.off
dev.off
dev.off()
dev.off()
dev.off()
for (i in 1:2){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp),
col = colpal[i],
add=T)
print(i)
}
}
lines(
ecdf(temp),
# col = colpal[i],
add=T)
for (i in 1:2){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp),
# col = colpal[i],
add=T)
print(i)
}
}
source('~/.active-rstudio-document', echo=TRUE)
for (i in 1:2){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
points(
ecdf(temp),
# col = colpal[i],
)
print(i)
}
}
points(
ecdf(temp)
# col = colpal[i],
)
for (i in 1:2){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
points(
ecdf(temp))
# col = colpal[i]
print(i)
}
}
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
for (i in 1:length(files)){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"))
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp))
# col = colpal[i]
print(i)
}
}
temp
plot(ecdf(temp),xlim=c(1,100))
plot(ecdf(temp),xlim=c(1,100),pch = 1)
plot(ecdf(temp),xlim=c(1,100),pch = 0)
plot(ecdf(temp),xlim=c(1,100),'l')
plot(ecdf(temp),xlim=c(1,100),do.points=F)
plot(ecdf(temp),xlim=c(1,100),do.points=F,lwd=2)
plot(ecdf(temp),xlim=c(1,50),do.points=F,lwd=2)
plot(ecdf(temp),xlim=c(1,40),do.points=F,lwd=2)
plot(ecdf(temp),xlim=c(1,20),do.points=F,lwd=2)
for (i in 1:length(files)){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"),
xlim=c(1,20),do.points=F,lwd=2)
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp))
# col = colpal[i]
print(i)
}
}
for (i in 1:length(files)){
colpal = viridis(length(files))
temp = ap_pdf(files[i],"Q_cfs",0.5)
if (i==1){
plot(
ecdf(temp),
col = colpal[i],
main = 'PDF of Reference Gauges',
xlab=("Number of No Flow Days"),
xlim=c(1,20),do.points=F,lwd=2)
}
else if(i>1 & length(temp)>1){
lines(
ecdf(temp),
col = colpal[i],
do.points=F,
lwd=2
)
print(i)
}
}
hist(temp)
hist(log(temp))
hist(log10(temp))
hist(temp)
temp = ap_pdf(files[i],"Q_cfs",0)
hist(temp)
ks.test(temp,'pnorm')
ks.test(temp,'plog')
ks.test(temp,'ppowe')
ks.test(temp,'ppower')
install.packages("car")
car::leveneTest(temp)
plot(temp)
rank(temp)
plot(rank(temp))
# library(plotrix)
library(here)
library(data.table)
library(ggplot2)
here()
obs = read.delim(here("allHF.txt"),header=FALSE)
install.packages('googledrive')
library(googledrive)
drive_find
drive_find()
drive_find(n=20)
setwd("/Volumes/GoogleDrive/My Drive/12_subprojects/DryingRegimes/code")
tt = read.csv('../data/gages_with_ecoregion.csv')
tt
View(tt)
tt$Name=="ignore"
tt$Name==ignore
tt$Name=="Ignore"
metdata = read.csv('../data/mean_annual_no_flow_and_climate_metric_means_for_no_flow_sites_082819_with_info.csv')
ws.dat = read.csv('../data/20200211_watershed_storage.csv')
percentile.dat = read.csv('../data/gages_percentile.csv')
library(tidyverse)
event = read.csv('../data/metrics_by_event.csv')
mean.event = event[,-c("calendar_year")]
mean.event = event[,c("gage")]
mean.event = event[,c("gage","peak_date","peak2zero","drying_rate","dry_date_start","dry_date_mean",'dry_dur')]
mean.event = event[,c("gage","peak_date","peak2zero","drying_rate","dry_date_start","dry_date_mean",'dry_dur')] %>% group_by(gage) %>% summarise(.,mean_drying_rate = mean(drying_rate),n_events = n())
View(mean.event)
install.packages("circular")
library(circular)
360/365
fact = 360/365
event$peak_date
event$peak_date = event$peak_date * fact
event$peak_date
circ = circular::circular(event$peak_date,units="degrees")
rose.diag(circ)
runif(50, 0, 2*pi)
x <- circular(runif(50, 0, 2*pi))
rose.diag(x, bins = 18, main = 'Uniform Data')
points(x)
rose.diag(circ,bins = 10)
rose.diag(circ,bins = 12)
rose.diag(circ,bins = 4)
x <- rvonmises(n=50, mu=circular(0), kappa=5, control.circular=list(zero=pi/4))
y <- rose.diag(x, bins=18) # Points fall out of bounds.
points(x, plot.info=y, stack=TRUE)
y <- rose.diag(x, bins=18, prop=1.5, shrink=1.5)
points(x, plot.info=y, stack=TRUE)
event$peak_date
sine(event$peak_date)
sin(event$peak_date)
View(event)
sin(event$peak_date*pi/180)
sin(0)
sin(1)
event$peak_date*pi/180
365*fact
0*fact
sin(360*pi/180)
sin(360*(pi/180)
sin(360*(pi/180)
)
sin(360*(pi/180))
sin(0*(pi/180))
sin(1*(pi/180))
sin(180*(pi/180))
180*(pi/180)
sin(pi)
sin(120)
cos(120)
cos(120*(pi/180))
sin(120*(pi/180))
sin(360*(pi/180))
pi/180
sin(0*(pi/180))
sin(365*(pi/180))
sin(180*(pi/180))
sin(180)
pi
sinpi(360)
sinpi(180)
sinpi(1)
sinpi()
sinpi(pi)
sinpi(pi/2)
sinpi(180*(pi/180))
sinpi(360*(pi/180))
sin(180*pi)
rad(360)
sin(rad(360))
sin(rad(0))
sin(rad(0.000001))
sin(2*pi)
sin(2*round(pi,4))
sin(180*(pi/180))
sin(181*(pi/180))
sin(182*(pi/180))
cos(120*pi/180)
cos(360*pi/180)
cos(0*pi/180)
cos(event$peak_date*pi/180)
cos(1*pi/180)
cos(2*pi/180)
sin(52.517*(pi/180))
cos(1*pi/180)
cos(344*pi/180)
cos(359*pi/180)
cos(1*pi/180)
cos(359*pi/180)
cos(2*pi/180)
cos(358*pi/180)
sin(event$peak_date*pi/180)
seq(0:24)
seq(0:24,24)
seq(0:24,1)
seq(0:24,from:0)
seq(0:24,from=0)
seq(0:23)
0:24
tt = 0:24
circ = circular::circular(tt,units="degrees")
circ
circ = circular::circular(tt,units="hours")
circ
tt = 0:360
circ = circular::circular(tt,units="degrees")
circ
plot(circ)
360/365
(360/365)/45
45/(360/365)
315*(pi/180)
315*fact
320*fact
event = read.csv('../data/metrics_by_event.csv')
event$peak_date_strans = event$peak_date * fact
event$peak_date_strans = sin((event$peak_date * fact)*(pi/180))
View(event)
var(event$peak_date)
unload(circular())
unload(circular
)
detach("package:circular", unload=TRUE)
var(event$peak_date)
summary(event$peak_date)
var(event$peak_date,rm.na=T)
var(event$peak_date,na.rm=T)
var(event$peak_date_strans)
var(event$peak_date_strans,na.rm=T)
var(scale(event$peak_date),na.rm=T)
var(scale(event$peak_date_strans),na.rm=T)
scale(event$peak_date_strans)
var(event$peak_date_strans,na.rm=T)
mean(event$peak_date,na.rm=T)
mean(event$peak_date,na.rm=T)/sd(event$peak_date,na.rm=T)
mean(event$peak_date_strans,na.rm=T)
mean(event$peak_date_strans,na.rm=T)/sd(event$peak_date_strans,na.rm=T)

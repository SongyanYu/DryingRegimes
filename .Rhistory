, "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
############## PCA ############
PCA = prcomp(dat.scale)
autoplot(PCA,loadings=T,loadings.label=T)
# Visualize eigenvalues/variances
fviz_screeplot(PCA, addlabels = TRUE, ylim = c(0, 50))
################### K-Means ######################
fviz_nbclust(dat.scale, kmeans, method = "silhouette") + theme_classic()
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=4)
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
fviz_cluster(wcke, geom = "point", ellipse.type = "norm", ggtheme = theme_minimal())
opt_gmm = Optimal_Clusters_GMM(dat.scale, max_clusters = 10, criterion = "BIC",
dist_mode = "maha_dist", seed_mode = "random_subset",
km_iter = 10, em_iter = 10, var_floor = 1e-10,
plot_data = T)
gmm = GMM(dat.scale, 5, dist_mode = "maha_dist", seed_mode = "random_subset", km_iter = 10,
em_iter = 10, verbose = F)
pr = predict_GMM(dat.scale, gmm$centroids, gmm$covariance_matrices, gmm$weights)
# Create distance matrix with scaled vars
d <- dat.scale %>%
vegdist(., method = 'euclidean')
#Use heirchal clustering
fit <- hclust(d, method = "ward")
plot(fit,
sub="Sampling Site",
hang=-0.5,
main = NULL,
labels = FALSE,
ylab="Height")
#After visual inspection, select where to cut the tree
df<- df %>%
mutate(
clust_4 = cutree(fit, k=5))
plot(fit,
sub="Sampling Site",
hang=-0.5,
main = NULL,
labels = FALSE,
ylab="Height")
title("Cluster Analysis: Ward's Mimium Variance (Euclidean Distance)", line = 3, cex =2)
title("4 Groups", line = 2)
rect.hclust(fit, k=5)
#After visual inspection, select where to cut the tree
df<- df %>%
mutate(
clust_4 = cutree(fit, k=4))
plot(fit,
sub="Sampling Site",
hang=-0.5,
main = NULL,
labels = FALSE,
ylab="Height")
title("Cluster Analysis: Ward's Mimium Variance (Euclidean Distance)", line = 3, cex =2)
title("4 Groups", line = 2)
rect.hclust(fit, k=4)
##################### Density Based Clustering #########################
library(fpc)
library(dbscan)
library(factoextra)
kNNdistplot(dat.scale,k = log(length(dat.scale)))
db = fpc::dbscan(dat.scale,eps=.5,MinPts = log(length(dat.scale)))
fviz_cluster(db,dat.scale, stand = FALSE, ellipse = FALSE, geom = "point",show.clust.cent = T,pointsize = .5)
# write.csv(clust,"../data/clustering_results.csv")
######## Plots ##########
# Color scale
cols <-
c("1" = "#4477AA",
"2" = "#66CCEE",
"3" = "#228833",
"4" = "#CCBB44",
"5" = "#EE6677",
"6" = "#AA3377",
"7" = "#BBBBBB",
"8" = "#999944",
"9" = "#332288")
PCA = prcomp(dat.scale)
var <- get_pca_var(PCA)
corrplot(var$cos2, is.corr=FALSE)
df_out <- as.data.frame(PCA$x)
df_out$group <- sapply( strsplit(as.character(row.names(df)), "_"), "[[", 1 )
head(df_out)
k_means <- ggplot(df_out,aes(x=PC1,y=PC2,col=factor(clust$kmeans.clust)))+
geom_point(size=3,alpha=0.5)+
scale_color_manual(name = "K-means Cluster",values = cols)+
theme_classic()
gmm.clust <- ggplot(df_out,aes(x=PC1,y=PC2,col=factor(clust$gmm.clust)))+
geom_point(size=3,alpha=0.5)+
scale_color_manual(name = "GMM Cluster",values = cols)+
theme_classic()
hier <- ggplot(df_out,aes(x=PC1,y=PC2,col=factor(clust$hier.4.clust)))+
geom_point(size=3,alpha=0.5)+
scale_color_manual(name = "Hierarchical Cluster",values = cols)+
theme_classic()
dbscan.clust <- ggplot(df_out,aes(x=PC1,y=PC2,col=factor(clust$dbscan.cluster)))+
geom_point(size=3,alpha=0.5)+
scale_color_manual(name = "DBSCAN Cluster",values = cols)+
theme_classic()
# Stats plot
dat.metrics = df %>% select("peak2zero","drying_rate",
"dry_date_start", "dry_dur",
"peak_quantile", "rel_freq")
h  = ggpairs(dat.metrics,
aes(color = as.factor(clust$hier.4.clust)))
for(i in 1:h$nrow) {
for(j in 1:h$ncol){
h[i,j] <- h[i,j] +
scale_fill_manual(values=cols) +
scale_color_manual(values=cols)
}
}
g = ggpairs(dat.metrics,
aes(color = as.factor(clust$gmm.clust)))
for(i in 1:g$nrow) {
for(j in 1:g$ncol){
g[i,j] <- g[i,j] +
scale_fill_manual(values=cols) +
scale_color_manual(values=cols)
}
}
k = ggpairs(dat.metrics,
aes(color = as.factor(clust$kmeans.clust)))
for(i in 1:k$nrow) {
for(j in 1:k$ncol){
k[i,j] <- k[i,j] +
scale_fill_manual(values=cols) +
scale_color_manual(values=cols)
}
}
d = ggpairs(dat.metrics,
aes(color = as.factor(clust$dbscan.clust)))
for(i in 1:d$nrow) {
for(j in 1:d$ncol){
d[i,j] <- d[i,j] +
scale_fill_manual(values=cols) +
scale_color_manual(values=cols)
}
}
h
g
k
d
clust = df %>% select(gage,Name,CLASS,dec_lat_va,dec_long_va,clust_4,peak2zero,drying_rate,dry_date_start, dry_dur,peak_quantile, rel_freq)
clust = cbind(clust,pr$cluster_labels+1,wcke$cluster,db$cluster+1)
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
clust = df %>% select(gage,Name,CLASS,dec_lat_va,dec_long_va,clust_4,peak2zero,drying_rate,dry_date_start, dry_dur,peak_quantile, rel_freq)
clust = cbind(clust,pr$cluster_labels+1,wcke$cluster,db$cluster+1)
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
library(tidyverse)
library(mclust)
library(ggplot2)
library(mapdata)
library(ggfortify)
library(plotly)
library(ClusterR)
library(cluster)
library(factoextra)
library(GGally)
library(vegan)
library(clustsig)
library(dplyr)
library(patchwork)
library(parallel)
library("corrplot")
library(scales)
df = read.csv("../data/metrics_by_event_combined_raw.csv")
df$Name[df$Name == "Ignore"] = "Mediterranean California"
df = df[df$peak_quantile>.25 & df$drying_rate>=0,]
#Rename event_id  (Somethign is weird here...)
df<-df %>%
mutate(event_id = seq(1, nrow(df)))
df = df %>% group_by(gage) %>% count() %>% left_join(df,.,by="gage")
fun<-function(n){
#Libraries of interest
library(dplyr)
#isolate event of interest
event <- df[n,]
#count number of events in same year and at same gage
count<- df %>%
filter(meteorologic_year == event$meteorologic_year) %>%
filter(gage == event$gage) %>%
nrow()
#Export info
tibble(
event_id = event$event_id,
freq_local = count
)
}
#run function
n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl, "df")
output<-parLapply(cl, seq(1,nrow(df)), fun)
remove(cl)
#add results to df
output<-bind_rows(output)
df<-left_join(df,output)
### Make rel_freq metric
df$rel_freq = df$freq_local/df$n
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate",
"dry_date_start", "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate"
, "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
rm(df)
rm(output)
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
#################### Load  and filter data #################
df = read.csv("../data/metrics_by_event_combined.csv")
df$Name[df$Name == "Ignore"] = "Mediterranean California"
df = df[df$peak_quantile>.25 & df$drying_rate>=0,]
#Rename event_id  (Somethign is weird here...)
df<-df %>%
mutate(event_id = seq(1, nrow(df)))
df = df %>% group_by(gage) %>% count() %>% left_join(df,.,by="gage")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Step 2: Estimate events per year ---------------------------------------------
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Create fun to estimate number of drying events in the same meterologic year per event
fun<-function(n){
#Libraries of interest
library(dplyr)
#isolate event of interest
event <- df[n,]
#count number of events in same year and at same gage
count<- df %>%
filter(meteorologic_year == event$meteorologic_year) %>%
filter(gage == event$gage) %>%
nrow()
#Export info
tibble(
event_id = event$event_id,
freq_local = count
)
}
#run function
n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl, "df")
output<-parLapply(cl, seq(1,nrow(df)), fun)
remove(cl)
#add results to df
output<-bind_rows(output)
df<-left_join(df,output)
### Make rel_freq metric
df$rel_freq = df$freq_local/df$n
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate",
"dry_date_start", "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate"
, "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
#################### Load  and filter data #################
df = read.csv("../data/metrics_by_event_combined_raw.csv")
df$Name[df$Name == "Ignore"] = "Mediterranean California"
df = df[df$peak_quantile>.25 & df$drying_rate>=0,]
#Rename event_id  (Somethign is weird here...)
df<-df %>%
mutate(event_id = seq(1, nrow(df)))
df = df %>% group_by(gage) %>% count() %>% left_join(df,.,by="gage")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Step 2: Estimate events per year ---------------------------------------------
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Create fun to estimate number of drying events in the same meterologic year per event
fun<-function(n){
#Libraries of interest
library(dplyr)
#isolate event of interest
event <- df[n,]
#count number of events in same year and at same gage
count<- df %>%
filter(meteorologic_year == event$meteorologic_year) %>%
filter(gage == event$gage) %>%
nrow()
#Export info
tibble(
event_id = event$event_id,
freq_local = count
)
}
#run function
n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl, "df")
output<-parLapply(cl, seq(1,nrow(df)), fun)
remove(cl)
#add results to df
output<-bind_rows(output)
df<-left_join(df,output)
### Make rel_freq metric
df$rel_freq = df$freq_local/df$n
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate",
"dry_date_start", "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
dat.scale <- df %>%
#Select vars of interest
select("peak2zero","drying_rate"
, "dry_dur",
"peak_quantile", "rel_freq") %>%
#scale vars
scale()
############## PCA ############
PCA = prcomp(dat.scale)
autoplot(PCA,loadings=T,loadings.label=T)
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
################### K-Means ######################
fviz_nbclust(dat.scale, kmeans, method = "silhouette") + theme_classic()
wcke<-eclust(dat.scale, "kmeans", hc_metric="euclidean",k=5)
dat = read.csv("../data/clustering_results_allevents.csv")
########## Define Colors
pal_regions <-
c("Eastern Forests" = "#009E73",
"Mediterranean California" = "#F0E442",
"Northern Great Plains" = "#0072B2",
"Southern Great Plains" = "#E69F00",
"Western Deserts" = "#D55E00",
"Western Mountains" = "#56B4E9")
cols <-
c("1" = "#4477AA",
"2" = "#66CCEE",
"3" = "#228833",
"4" = "#CCBB44",
"5" = "#EE6677",
"6" = "#AA3377",
"7" = "#BBBBBB",
"8" = "#999944",
"9" = "#332288")
dat = read.csv("../data/clustering_results_allevents.csv")
dat = read.csv("data/clustering_results_allevents.csv")
# Summarize Data
##Kmeans
library(dplyr)
tt <- dat  %>%
group_by(dry_date_start,kmeans.clust) %>%
summarise(n = sum(kmeans.clust)) %>%
mutate(percentage = round(n / sum(n),4))
View(tt)
k = ggplot(tt, aes(x=dry_date_start, y=percentage, fill=factor(kmeans.clust))) +
geom_area(alpha=n , size=.5, colour="black")+
scale_fill_manual(values=cols,"Cluster Membership")+
ggtitle("Kmeans")+
plot_lay()
library(ggridges)
library(ggplot2)
library(dplyr)
library(lubridate)
library(ggpubr)
library(RColorBrewer)
library(tidyverse)
library(patchwork)
library(viridis)
tt <- dat  %>%
group_by(dry_date_start,kmeans.clust) %>%
summarise(n = sum(kmeans.clust)) %>%
mutate(percentage = round(n / sum(n),4))
k = ggplot(tt, aes(x=dry_date_start, y=percentage, fill=factor(kmeans.clust))) +
geom_area(alpha=n , size=.5, colour="black")+
scale_fill_manual(values=cols,"Cluster Membership")+
ggtitle("Kmeans")+
plot_lay()
plot_lay <-function(){
list(
theme_bw(),
ylab('Proportion of Drying Events'),
xlab('Julian Date'),
#Axes Options
theme(
axis.title = element_text(size=14),
axis.text  = element_text(size = 10)),
#Legend Options
theme(legend.position = "bottom",
legend.title = element_text(size=14),
legend.text = element_text(size=10))
)
}
# Summarize Data
##Kmeans
library(dplyr)
tt <- dat  %>%
group_by(dry_date_start,kmeans.clust) %>%
summarise(n = sum(kmeans.clust)) %>%
mutate(percentage = round(n / sum(n),4))
k = ggplot(tt, aes(x=dry_date_start, y=percentage, fill=factor(kmeans.clust))) +
geom_area(alpha=n , size=.5, colour="black")+
scale_fill_manual(values=cols,"Cluster Membership")+
ggtitle("Kmeans")+
plot_lay()
k
k = ggplot(tt, aes(x=dry_date_start, y=percentage, fill=factor(kmeans.clust))) +
geom_area(size=.5, colour="black")+
scale_fill_manual(values=cols,"Cluster Membership")+
ggtitle("Kmeans")+
plot_lay()
k
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = cummean(n))
View(yy)
library(zoo)
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = rollmean(n,10,na.pad = FALSE))
View(yy)
rm(yy)
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = rollmean(n,10,na.pad = FALSE))
View(yy)
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(n,10,na.pad = FALSE))
tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(n,10,na.pad = FALSE))
tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(n,10,na.pad = T))
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(n,10,na.pad = T))
View(yy)
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(n,5,na.pad = T))
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(percentage,5,na.pad = T))
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(percentage,2,na.pad = T))
yy = tt %>% group_by(dry_date_start)%>%
mutate(mov.avg = zoo::rollmean(percentage,2,na.pad = T))
View(yy)
yy = tt %>% group_by(dry_date_start)%>%
mutate(mov.avg = zoo::rollmean(percentage,10,na.pad = T))
yy = tt %>% group_by(dry_date_start)%>%
mutate(mov.avg = zoo::rollmean(percentage,5,na.pad = T))
yy = tt %>% group_by(kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(percentage,5,na.pad = T))
View(yy)
yy = tt %>% group_by(dry_date_start,kmeans.clust)%>%
mutate(mov.avg = zoo::rollmean(percentage,5,na.pad = T))
View(yy)
)
tt %>% flatten()
pp = tt %>% flatten()
View(pp)
spread(tt)
spread(tt,kmeans.clust)
tt %>% spread(.,kmeans.clust)
tt %>% spread(dry_date_start,kmeans.clust)
yy = tt %>% spread(dry_date_start,kmeans.clust)
yy = tt %>% spread(n,kmeans.clust)
pp = tt
pp$k.clust = paste("kmeans.",pp$kmeans.clust)
pp$k.clust = paste0("kmeans.",pp$kmeans.clust)
yy = tt %>% spread(n,k.clust)
yy = pp %>% spread(n,k.clust)
View(yy)
yy = pp %>% spread(k.clust,percentile)
yy = pp %>% spread(k.clust,percentage)
View(yy)
pp$kmeans.clust = NULL
yy = pp %>% spread(k.clust,percentage)
View(yy)
yy = pp %>% select(dry_date_start,k.clust,percentage) spread(k.clust,percentage)
yy = pp %>% select(dry_date_start,k.clust,percentage) %>% spread(k.clust,percentage)
View(yy)
yy = pp %>%
select(dry_date_start,k.clust,percentage) %>%
spread(k.clust,percentage) %>%
mutate(mov.avg = zoo::rollmean(k.clust,5,na.pad = T))
yy = pp %>%
select(dry_date_start,k.clust,percentage) %>%
spread(k.clust,percentage) %>%
mutate(mov.avg = zoo::rollmean(kmeans.1,5,na.pad = T))
View(yy)
yy = pp %>%
select(dry_date_start,k.clust,percentage) %>%
spread(k.clust,percentage) %>%
mutate(mov.avg = zoo::rollmean(kmeans.1,2,na.pad = T))
yy = pp %>%
select(dry_date_start,k.clust,percentage) %>%
spread(k.clust,percentage) %>%
mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = F))
yy = pp %>%
select(dry_date_start,k.clust,percentage) %>%
spread(k.clust,percentage) %>%
mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = T))
pp = yy%>%mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = T))
pp = tt
kk = yy%>%mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = T))
kk = yy%>%select(dry_date_start,kmeans.1) %>% mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = T))
kk = yy%>%select(dry_date_start,kmeans.1) %>% mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,na.pad = T,align="right"))
View(kk)
kk = yy%>%select(dry_date_start,kmeans.1) %>% mutate(mov.avg = zoo::rollmean(kmeans.1,k=2,fill=NA,align="right"))
kk = yy%>%select(dry_date_start,s=kmeans.1) %>% mutate(mov.avg = zoo::rollmean(s,k=2,fill=NA,align="right"))
